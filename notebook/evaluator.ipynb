{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6428bc03",
      "metadata": {},
      "source": [
        "# Multi-Sequence Polyline Evaluation\n",
        "\n",
        "Evaluates generated polylines for selected dataset sequences (`file_idx`).\n",
        "\n",
        "- **Data Structure**:\n",
        "  - Root: `data/issue/converted_bin/{file_idx}/`\n",
        "  - GT: `{file_idx}/points_seq_1.bin` (Header + 6 floats/point)\n",
        "  - Trajectory: `{file_idx}/vehicle_trajectory.bin`\n",
        "  - Merged Polylines: `{file_idx}/merged_polylines/frame_*.bin` (Complex Structure)\n",
        "  \n",
        "- **Metric**: Chamfer Distance (Precision/Recall) within ROI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f5406b16",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import KDTree\n",
        "import struct\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ba5c0de",
      "metadata": {},
      "source": [
        "## 1. Configuration & Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f3bb4a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CONFIGURATION ---\n",
        "WS_PATH = os.path.abspath(\"../\") \n",
        "if not os.path.exists(os.path.join(WS_PATH, \"data\")): \n",
        "    WS_PATH = \"/Users/sukhosong/RideFlux/toy_map_viewer\"\n",
        "\n",
        "BASE_DATA_DIR = os.path.join(WS_PATH, \"data/issue/converted_bin\")\n",
        "GT_FILENAME = \"points_seq_1.bin\"\n",
        "\n",
        "# Select Targets: List of strings ['0', '1'] or None for 'All'\n",
        "TARGET_SEQUENCES = ['3'] \n",
        "\n",
        "# Parameters\n",
        "ROI_RADIUS = 30.0    \n",
        "MATCH_DIST_TH = 0.5\n",
        "DENSIFY_DRAFT = True\n",
        "DENSIFY_STEP = MATCH_DIST_TH * 0.5  # Smaller than MATCH_DIST_TH\n",
        "\n",
        "# --- HELPERS ---\n",
        "def read_points_bin(filename):\n",
        "    \"\"\"Reads Point Cloud (Header+Stride=24) or (Stride=16)\"\"\"\n",
        "    if not os.path.exists(filename): return np.array([])\n",
        "    with open(filename, 'rb') as f:\n",
        "        header = f.read(4)\n",
        "        if len(header) < 4: return np.array([])\n",
        "        \n",
        "        content = f.read()\n",
        "        # Try Stride 24 (6 floats)\n",
        "        if len(content) % 24 == 0:\n",
        "             num_points = len(content) // 24\n",
        "             data = struct.unpack(f'{num_points*6}f', content)\n",
        "             points = np.array(data).reshape(-1, 6)\n",
        "        # Try Stride 16 (4 floats)\n",
        "        elif len(content) % 16 == 0:\n",
        "             num_points = len(content) // 16\n",
        "             data = struct.unpack(f'{num_points*4}f', content)\n",
        "             points = np.array(data).reshape(-1, 4)\n",
        "        else:\n",
        "             return np.array([])\n",
        "    return points[:, :3]\n",
        "\n",
        "def read_custom_polylines_bin_polylines(filename):\n",
        "    \"\"\"Reads Complex Polyline Binary Format and returns list of polylines\"\"\"\n",
        "    points_list = []\n",
        "    if not os.path.exists(filename): return points_list\n",
        "    \n",
        "    with open(filename, 'rb') as f:\n",
        "        # 1. Total Polyline Num\n",
        "        data = f.read(4)\n",
        "        if len(data) < 4: return points_list\n",
        "        total_poly_num = struct.unpack('I', data)[0]\n",
        "        \n",
        "        for _ in range(total_poly_num):\n",
        "            # 2. ID(4), Layer(4), Size(4) => 12 bytes\n",
        "            meta = f.read(12)\n",
        "            if len(meta) < 12: break\n",
        "            pid, layer, p_size = struct.unpack('iiI', meta)\n",
        "            \n",
        "            # 3. Points (p_size * 12 bytes => x,y,z)\n",
        "            raw_pts = f.read(p_size * 12)\n",
        "            if len(raw_pts) < p_size * 12: break\n",
        "            \n",
        "            pts = struct.unpack(f'{p_size*3}f', raw_pts)\n",
        "            pts = np.array(pts).reshape(-1, 3)\n",
        "            points_list.append(pts)\n",
        "    \n",
        "    return points_list\n",
        "\n",
        "def flatten_polylines(polylines):\n",
        "    if not polylines: return np.array([])\n",
        "    return np.vstack(polylines)\n",
        "\n",
        "def densify_polyline(polyline, step):\n",
        "    if step is None or step <= 0 or len(polyline) == 0:\n",
        "        return polyline\n",
        "    out = [polyline[0]]\n",
        "    for i in range(1, len(polyline)):\n",
        "        p0 = polyline[i - 1]\n",
        "        p1 = polyline[i]\n",
        "        vec = p1 - p0\n",
        "        dist = np.linalg.norm(vec)\n",
        "        if dist == 0:\n",
        "            continue\n",
        "        direction = vec / dist\n",
        "        num = int(dist // step)\n",
        "        for k in range(1, num + 1):\n",
        "            t = step * k\n",
        "            if t >= dist:\n",
        "                break\n",
        "            out.append(p0 + direction * t)\n",
        "        out.append(p1)\n",
        "    return np.vstack(out)\n",
        "\n",
        "def densify_polylines(polylines, step):\n",
        "    if step is None or step <= 0:\n",
        "        return polylines\n",
        "    densified = []\n",
        "    for polyline in polylines:\n",
        "        if len(polyline) == 0:\n",
        "            continue\n",
        "        densified.append(densify_polyline(polyline, step))\n",
        "    return densified\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "j9szcqoolk",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 1 sequences: ['0']\n",
            "=== Processing Sequence: 0 ===\n",
            "GT missing/empty, skipping.\n"
          ]
        }
      ],
      "source": [
        "# Determine Subdirectories\n",
        "if TARGET_SEQUENCES is None:\n",
        "    seq_dirs = sorted(glob.glob(os.path.join(BASE_DATA_DIR, \"*\")))\n",
        "    seq_dirs = [d for d in seq_dirs if os.path.isdir(d)]\n",
        "else:\n",
        "    # Verify specified targets exist\n",
        "    seq_dirs = []\n",
        "    for t in TARGET_SEQUENCES:\n",
        "        p = os.path.join(BASE_DATA_DIR, t)\n",
        "        if os.path.isdir(p):\n",
        "            seq_dirs.append(p)\n",
        "        else:\n",
        "            print(f\"[WARN] Target sequence '{t}' not found at {p}\")\n",
        "\n",
        "print(f\"Processing {len(seq_dirs)} sequences: {[os.path.basename(d) for d in seq_dirs]}\")\n",
        "\n",
        "overall_stats = {}\n",
        "\n",
        "for seq_dir in seq_dirs:\n",
        "    seq_name = os.path.basename(seq_dir)\n",
        "    print(f\"=== Processing Sequence: {seq_name} ===\")\n",
        "    \n",
        "    # 1. Load GT\n",
        "    gt_file = os.path.join(seq_dir, GT_FILENAME)\n",
        "    gt_points = read_points_bin(gt_file)\n",
        "    \n",
        "    if len(gt_points) == 0:\n",
        "        print(\"GT missing/empty, skipping.\")\n",
        "        continue\n",
        "    gt_tree = KDTree(gt_points[:, :2])\n",
        "    \n",
        "    # 2. Load Trajectory\n",
        "    traj_file = os.path.join(seq_dir, \"vehicle_trajectory.bin\")\n",
        "    traj_points = read_points_bin(traj_file)\n",
        "    if len(traj_points) == 0:\n",
        "        print(\"Trajectory missing, skipping.\")\n",
        "        continue\n",
        "        \n",
        "    draft_dir = os.path.join(seq_dir, \"merged_polylines\")\n",
        "    seq_results = {\n",
        "        'frames': [], 'precision': [], 'recall': [], 'f1': [],\n",
        "        'TP': [], 'FP': [], 'FN_G': [], # FN_G: Mean False Negative from GT perspective\n",
        "        'gt_roi_count': [], 'draft_roi_count': []\n",
        "    }\n",
        "    \n",
        "    num_frames = traj_points.shape[0]\n",
        "    print(f\"  Evaluating {num_frames} frames...\")\n",
        "    \n",
        "    for i in range(num_frames):\n",
        "        ego_pos = traj_points[i, :2]\n",
        "        \n",
        "        # Load Draft with CUSTOM PARSER\n",
        "        draft_path = os.path.join(draft_dir, f\"{i}.bin\")\n",
        "        if not os.path.exists(draft_path): draft_path = os.path.join(draft_dir, f\"frame_{i}.bin\")\n",
        "        if not os.path.exists(draft_path): draft_path = os.path.join(draft_dir, f\"{i:04d}.bin\")\n",
        "        \n",
        "        draft_polylines = read_custom_polylines_bin_polylines(draft_path)\n",
        "        if DENSIFY_DRAFT and draft_polylines:\n",
        "            draft_polylines = densify_polylines(draft_polylines, DENSIFY_STEP)\n",
        "        draft_points = flatten_polylines(draft_polylines)\n",
        "        \n",
        "        # ROI Filter GT\n",
        "        gt_indices = gt_tree.query_ball_point(ego_pos, ROI_RADIUS)\n",
        "        gt_roi_count = len(gt_indices)\n",
        "        \n",
        "        # ROI Filter Draft\n",
        "        draft_roi_idx = []\n",
        "        if len(draft_points) > 0:\n",
        "            draft_tree_tmp = KDTree(draft_points[:, :2])\n",
        "            draft_roi_idx = draft_tree_tmp.query_ball_point(ego_pos, ROI_RADIUS)\n",
        "        draft_roi_count = len(draft_roi_idx)\n",
        "        \n",
        "        precision, recall, f1 = 0.0, 0.0, 0.0\n",
        "        tp_count, fp_count, fn_count = 0, 0, 0\n",
        "        \n",
        "        if len(gt_indices) == 0:\n",
        "            # No GT in this area\n",
        "            if len(draft_points) > 0: \n",
        "                # Only False Positives\n",
        "                precision=0.0; recall=1.0; f1=0.0\n",
        "                fp_count = len(draft_points)\n",
        "            else:\n",
        "                # Perfect (Empty matches Empty)\n",
        "                precision=1.0; recall=1.0; f1=1.0\n",
        "        else:\n",
        "            gt_local = gt_points[gt_indices]\n",
        "            fn_count = len(gt_local)\n",
        "            \n",
        "            if len(draft_points) == 0:\n",
        "                # Missed everything\n",
        "                precision=1.0; recall=0.0; f1=0.0\n",
        "            else:\n",
        "                if len(draft_roi_idx) == 0:\n",
        "                    precision=1.0; recall=0.0; f1=0.0\n",
        "                else:\n",
        "                    draft_local = draft_points[draft_roi_idx]\n",
        "                    \n",
        "                    # --- Precision Side (Draft -> GT) ---\n",
        "                    # Each Draft Point is TP if dist < TH, else FP\n",
        "                    draft_tree_local = KDTree(draft_local[:, :2])\n",
        "                    gt_tree_local = KDTree(gt_local[:, :2])\n",
        "                    \n",
        "                    dists_d2g, _ = gt_tree_local.query(draft_local[:, :2])\n",
        "                    is_tp_d = dists_d2g < MATCH_DIST_TH\n",
        "                    \n",
        "                    tp_count_p = np.sum(is_tp_d)          # TP (Precision view)\n",
        "                    fp_count = len(draft_local) - tp_count_p  # FP\n",
        "                    prec = tp_count_p / len(draft_local)\n",
        "                    \n",
        "                    # --- Recall Side (GT -> Draft) ---\n",
        "                    # Each GT Point is Maintained or Missed\n",
        "                    dists_g2d, _ = draft_tree_local.query(gt_local[:, :2])\n",
        "                    is_tp_g = dists_g2d < MATCH_DIST_TH\n",
        "                    \n",
        "                    tp_count_r = np.sum(is_tp_g)          # TP (Recall view, Many-to-One)\n",
        "                    fn_count = len(gt_local) - tp_count_r     # FN\n",
        "                    rec = tp_count_r / len(gt_local)\n",
        "                    \n",
        "                    # Final Metrics\n",
        "                    precision = prec\n",
        "                    recall = rec\n",
        "                    f1 = 2*(prec*rec)/(prec+rec) if (prec+rec)>0 else 0.0\n",
        "                    tp_count = tp_count_p # Use Precision's TP count for display\n",
        "        \n",
        "        seq_results['frames'].append(i)\n",
        "        seq_results['precision'].append(precision)\n",
        "        seq_results['recall'].append(recall)\n",
        "        seq_results['f1'].append(f1)\n",
        "        seq_results['TP'].append(tp_count)\n",
        "        seq_results['FP'].append(fp_count)\n",
        "        seq_results['FN_G'].append(fn_count)\n",
        "        seq_results['gt_roi_count'].append(gt_roi_count)\n",
        "        seq_results['draft_roi_count'].append(draft_roi_count)\n",
        "        \n",
        "    if len(seq_results['f1']) > 0:\n",
        "        mean_prec = np.mean(seq_results['precision'])\n",
        "        mean_rec = np.mean(seq_results['recall'])\n",
        "        mean_f1 = np.mean(seq_results['f1'])\n",
        "        overall_stats[seq_name] = {'precision': mean_prec, 'recall': mean_rec, 'f1': mean_f1}\n",
        "        print(f\"  -> Mean Prec: {mean_prec:.4f}, Mean Rec: {mean_rec:.4f}, Mean F1: {mean_f1:.4f}\")\n",
        "        \n",
        "        # Plot 1: Metrics\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        \n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(seq_results['precision'], label='Precision', color='green', alpha=0.6, linestyle='--')\n",
        "        plt.plot(seq_results['recall'], label='Recall', color='orange', alpha=0.6, linestyle='--')\n",
        "        plt.plot(seq_results['f1'], label='F1', color='blue', linewidth=2)\n",
        "        plt.title(f\"Seq {seq_name} Performance Metrics\")\n",
        "        plt.ylabel(\"Score\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.ylim(-0.05, 1.05)\n",
        "        \n",
        "        # Plot 2: Counts (TP, FP, FN)\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(seq_results['TP'], label='TP (Correct Draft Pts)', color='green', alpha=0.7)\n",
        "        plt.plot(seq_results['FP'], label='FP (Hallucinated)', color='red', alpha=0.7)\n",
        "        plt.plot(seq_results['FN_G'], label='FN (Missed GT Pts)', color='orange', alpha=0.5)\n",
        "        plt.title(\"Point Counts Breakdown\")\n",
        "        plt.ylabel(\"# Points\")\n",
        "        plt.xlabel(\"Frame ID\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Plot 3: ROI Total Counts (GT vs Merged)\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.plot(seq_results['draft_roi_count'], label='Merged ROI Points', color='purple', alpha=0.7)\n",
        "        plt.plot(seq_results['gt_roi_count'], label='GT ROI Points', color='black', alpha=0.7)\n",
        "        plt.title(f\"Seq {seq_name} ROI Point Counts\")\n",
        "        plt.ylabel(\"# Points\")\n",
        "        plt.xlabel(\"Frame ID\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"  -> No frames evaluated\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d60d229d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
